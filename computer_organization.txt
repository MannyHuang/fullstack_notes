/******************************************************************************************************
Computer Organization
*******************************************************************************************************/
1.Essences:
	1.Processor:
		1.Control Unit: control everything (modify this, if you have a better understanding
			1.IR (Instruction Register): stores current instructions
			2.PC (Program Counter): stores address of next instructions
		2.Arithmetic Logic Unit: calculations on register value
			1.General Purpose Registers: holding operands for instructions
	2.Memory:
		1.Memory: store program instructions and data
		2.Cache: store instruction currently being executed (on the same die as processor)
		3.Secondary storage: store program and data permanently
	3.I/O
	
2.Number Representation and Arithmetic Operation:
	1.Integers:
		1.three systems:
			1.sign and magnitude (worst for arithmetic, complement MSB for negative)
			2.1's complement (intermediate for arithmetic, complement all bits)
			3.2's complement (most efficient for arithmetic, adding 1 to 1's complement)
		2.Arithmetic for 2's complement:
			1.representation range: -2^(n-1) <->  2^(n-1)-1
			2.sign extension: repeat the MSB multiple times
			3.addition: add the n-bit representation, discard carries
			4.subtraction: complement the operand, do the add operation, discard carries
		3.detection of overflow:
			1.unsigned: overflow when carry form MSB is 1
			2.signed:
				1.summands have different signs: impossible to overflow 
				2.addition: overflow when resulted MSB is different from those of the summands
				3.subtraction:(modify this, if you have a better understanding
	2.Floating Point Numbers:
		1.Three Components:
			1.sign bit:1 bits
			2.significant bits: 23 bits
			3.exponent bits: 8bits
	3.Character Representation:
		1.encoded using the ASCII encoding standard (8 bits)

3.Performance
	1.Fabrication technology (smaller channel length)
		1.faster instruction execution (due to faster switching of logical states)
		2.more logic functionality and memory (more transistors per area)
	2.Parallelism
		1.Instruction level parallelism (pipe-lining)
			1.essence: overlapping successive instructions
		2.Multi-core Processing
			1.essence: instantiation of multiple processing units (cores) to form  a processor (the whole chip)
		3.Multiprocessor:
			1.essence: multiple multi-core processors to form a single processor
			1.shared-memory multiprocessor: all processors have access to all memory
			2.message-passing multicomputers
	


4.Instruction Set Architecture
	1.Memory Location and Addresses
		1.Address Space:
			1.24bit address space: 16M
			2.32bit address space: 4G
		2.Endian System:
			1.Little Endian: LSB stores in smaller address
			2.Big Endian: MSB stores in bigger address
		3.Alignment:
			1.aligned address: word start at the natural boundary (0, 4, 8 in case of 32bit word)
			2.non-aligned address: word stored randomly
		3.Addressing numbers and characters:
			1.addressing number: access by word address
			2.addressing character: access by byte address
	2.Instruction and Instruction Sequencing
		1. 4 Key Elements of Instructions:
			1.data transfer between memory and registers
			2.arithmetic and logic operations
			3.program sequencing and control
			4.I/O transfer
	3.RISC and CISC Instruction Sets
		1.RISC (Reduced Instruction set computer):
			1.essence:
				1.each instruction occupies exactly one word in memory 
				2.a store/load architecture is used
					1.memory operands accessed only using store/load instruction
					2.operands for arithmetic and logic operations stored in processor registers or given explicitly
				3.complexity lies in software (need sophisticated compiler), need more instructions(consumes memory), faster performance (pipe-lining)
			2.advantage:
				1.better for pipe-lining instructions 
			3.Mechanism:
				1.Instruction Sequencing and straight-line execution
					1.straight-line sequencing: fetch and execute instruction using info in PC, in order of increasing address
					2.Two phase instruction execution:
						1.instruction fetch: using info from PC to fetch instruction into IR
						2.instruction execute: execute instruction form IR
				2.Branching:
					1.(modify this, if you have a better understanding)
			4.Addressing modes:
				1.essence: different ways of specifying the locations of instruction operands
		2.CISC (Complex Instruction Set computer):
			1.essence:more 
				1.complex instructions that use more than one word
				2.prevalent before 1970s
				3.complexity lies in hardware, need less instruction, slower performance
	4.Assembly Language
		1.object program: assembled machine language program

		
5.Basic I/O
	1.memory mapped I/O: I/O registers mapped to an address in the address space (share the address space with the main memory)

	
6.Pipeline Hazards:
	1.RAW (read after write):
		1.essence: 
			1.data flow dependencies
			2.cannot be resolved by register renaming
	2.WAR (write after read):
		1.essence
			1.anti-dependencies
			2.instructions use same reg/mem locations, but no data flow
			3.can be resolved by register renaming
	3.WAW 
		1.essence:
			1.output dependencies
			2.instructions use same reg/mem locations, but no data flow
			3.can be resolved by register renaming
	
	
6.Dynamic Scheduling Algorithms
	1.Scheduling Algorithm one: Tomasulo
		1.Key structures:
			1.Reservation stations (instruction buffers)
			2.Common data bus (Broadcasting results to RS)
			3.Map table (map name to SRAM index)
		2.Key ideas:
			1.Register renaming:
				1.rename registers in hardware
				2.same register name can have multiple locations
				3.remove WAR & WAW, preserve RAW
		2.Map Table:
			1.Write: allocate new location & note in the map table
			2.Read: find location of most recent write
			3.Tag: RS#
				1.interpreted as ready bits
					1.0, register value ready
					2.not 0, wait till  CDB broadcasts
		3.Reservation stations (RS):
			1.Functional unit: FP,integer compute unit, AGU 
			2.status: busy/not busy
			3.OP: instruction OP
			4.Qj, Qk: RS# that produce value for register operand
			5.Vj.Vk: value of register operand
		4.Common data bus (CDB)::
			1.broadcast value with tags attached
		5.Pipeline
			1.Fetch:
				1.fetch inst from mem
			2.Dispatch:
				1.stall for structural hazard
					1.if RS not available
				2.Update Reservation station
					1.Check map table
						1.if reg ready, read value from reg file into RS
						2.if reg not ready, read RS# into RS
					2.update map table
					
						1.rename output reg
			3.Issue:
				1.wait for RAW hazards
					1.check if both input registers are available
				2.read reg values from RS & send to execute
			4.execute: (the cycle of dispatch + latency)
				1.execute the operation
				2.includes mem operation
			5.Writeback:
				1.wait for structural hazard (CDB)
				2.CDB broadcasts to Map table
						1.clear,write to register
				3.CDB broadcasts to RS
					1.if tag match, clear tag, copy value
				4.free RS entry
				5.pending issue can start if now both register ready

	2.True Register Renaming (MIPSR10K Design)
		1.Essence:
			1.True register renaming + reorder buffer
			2.precise state:
				1.abort & restart at every instruction
		2.Key structure:
			1.ROB
				1.essence a FIFO queue
					1.FLAG indicate completion
					2.new and old register mapping

Midterm review:
1.Metrics:
	1.CPU performance Equation:	
		1.Dynamic Instruction Count
			1.Dependency: program, compiler, ISA
		2.CPI
			1.Dependency: micro-architecture, ISA
			2.calculation: CPI = inst ratio * latency
		3.Clock period
			1.Dependency: micro-architecture, technology
	2.Speedup(or slowdown):
		1.speedup = T_old/T_new = (InstCount_old * CPI_old * CLK_old) / (InstCount_new * CPI_new * CLK_new)
	3.Benchmarks
		1.hardware performance counters
		2.dynamic binary instrumentation

2.Single cycle instruction:
	1.Datapath:
		1.inst cache + inst decoder + Source operand decoder + RF(read) + MUX + ALU + RF(write)		
3.Pipeline Implementation:
	1.Evaluation:
		1.Pros:
			1.High throughput
				1.every pipeline stage can handle a different instruction (compare to 1 inst in the entire datapath)
		2.Cons:
			1.High Latency
				1.pipeline overheads: extra bypassing logic
				2.All instruction must go though all stages even if not needed
					1.structural hazard otherwise 
						1.ex. add write to RF at M + load write to RF at W simultaneously
			2.Hazards
				1.more pipe-lining == more hazards
	2.Design guideline: 
		1.balanced/maximize throughput
		2.optimization 
			1.targets stages with highest latency
			2.speed up the common case:
				1.speedup = 1/(1-f+f/n)
		3.clock cycle = stage of highest latency + pipeline overhead(setup + register delay)
	3.Hazards
		1.Conditions for hazards
			1.potential to execute the both instructions in wrong order
			2.both instructions in pipeline simultaneously
		2.Types of Hazards
			1.RAW: add r2,r3->r1 => sub r1,r4->r2
			2.WAW: add r2,r3->r1 => sub r1,r4->r2 => or r6,r3->r1
			3.WAR: add r2,r3->r1 => sub r5,r4->r2
	4.Forwarding (or bypassing)	
		1.Types:
			1.MX(RR):add r2,r3->r1 => add r2,r3->r1 *r1*
			2.WX(RMR):add r2,r3->r1 => ld [r7]->r5 => sub r1,r4->r2 *r1*
			3.WM(MR):lw 0(r2)->r1 => sw r1->0(r4)
		2.Implementation:
			1.direct the output of pipeline register to the data   input of FUs
	5.Exception Handling
		1.handled when exceptions are ready to Writeback, not when occurred
		2.handled in program order, not temporal order
4.Branch Prediction
	1.history pattern table (HBT)
		1.preparation
			1.prepare all pattern history before hand if outcome available
		2.procedures
			1.write prediction (by looking up pattern)
			2.update prediction fro the pattern (using actual outcomes)
			3.update history pattern 
	2.HBT width requirement
		1.ex. for (i=0; i<4; i++) => 4bits required
	3.miss prediction rate = #of miss predictions / # of total predictions				
5.Dynamic Scheduling
	1.hardware vs software (hardware wins)
		1.better dynamic knowledges(cache miss, mispredilection, mem address)
		2.easier to speculater and recover
		3.more register
		4.more portable
	2.register renaming
		1.rename the 1st output reg
		2.rename the WAR and WAW, skip any already renamed
		
/********************************************************************************************************
Storage
********************************************************************************************************/
1.Endian System
	1.Little Endian: least significant bytes stored in smaller addresses
	2.Big Endian: least significant bytes stored in biggest addressess

1.SRAM (Static random access memory)
	1.no refreshing cycle
	2.data and address bus directly accessible
	3.fundamental storage elements: registers (occupy more area than caps)
	4.need dc power to retain memory

2.SDRAM (Synchronous Dynamic Access memory)
	1.needs frequent refreshing
	2.performance depends on access time and clock cycle coordination
	3.fundamental storage elements: caps
	4.high power consumption due to refreshing
	